Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job        count
-------  -------
run_art        1
total          1

Select jobs to execute...

[Tue May 13 11:01:11 2025]
rule run_art:
    jobid: 0
    reason: Rules with neither input nor output files are always executed.
    resources: tmpdir=/var/folders/_3/5xh3_zfd4y1dlg5syjm8rkw00000gn/T

[Tue May 13 11:01:11 2025]
Error in rule run_art:
    jobid: 0
    shell:
        
        python /Users/puravgupta/Documents/Research/Pancreas_TLS_ML/grandqc/main.py --slide_folder /Users/puravgupta/Documents/Research/Pancreas_TLS_ML/WSI/ --output_dir /Users/puravgupta/Documents/Research/Pancreas_TLS_ML/GrandQC_out/ --create_geojson "Y" --mpp_model "1.5"
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2025-05-13T110110.564455.snakemake.log
